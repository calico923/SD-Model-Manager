---
name: bug-reproduction
description: Generate bug reproduction checklist from symptoms, logs, and error traces for SD-Model-Manager
model: haiku
tools:
  - Read
  - Grep
  - Bash
  - Write
---

# Bug Reproduction Assistant

Lightweight agent for generating structured bug reproduction checklists from symptoms, logs, and error traces.

## Purpose

Standardize bug reporting and improve reproducibility by:
1. **Symptom Extraction**: Parse error messages and stack traces
2. **Log Analysis**: Find relevant log entries with rg/grep
3. **Command Generation**: Create reproduction steps with actual commands
4. **Checkpoint Definition**: Specify what to check (logs, DB, UI state)
5. **Checklist Output**: Generate actionable reproduction checklist

## Activation

**Trigger**: Manual invocation when bug is detected
**Output**: `docs/progress-reports/bug-[YYYYMMDD]-[short-description].md`

**Example**:
```
"Generate bug reproduction checklist for scanner crash on empty directory"
"Create reproduction steps for Civitai metadata parsing failure"
```

---

## Workflow

### Phase 1: Information Gathering

**Step 1**: Extract error information
```bash
# Get recent error logs (if log file exists)
tail -50 logs/app.log 2>/dev/null | rg -i "error|exception|traceback"

# Search for error patterns in code
rg -A 5 "raise.*Error" src/sd_model_manager/
```

**Step 2**: Identify affected components
```bash
# Find related source files
rg -l "class.*Scanner|def.*scan" src/sd_model_manager/

# Find related tests
rg -l "test.*scan" tests/sd_model_manager/
```

**Step 3**: Check recent changes
```bash
# Show recent commits affecting component
git log --oneline -10 -- src/sd_model_manager/registry/scanner.py

# Show recent changes to related files
git diff HEAD~5 -- src/sd_model_manager/registry/
```

### Phase 2: Reproduction Steps Generation

**Step 1**: Identify setup requirements
```markdown
**Environment**:
- Python version: [from pyproject.toml]
- Dependencies: [from pyproject.toml]
- Configuration: [relevant config settings]

**Test Data**:
- Directory structure needed
- File types required
- Metadata files (if applicable)
```

**Step 2**: Generate command sequence
```bash
# Example commands for scanner bug
python -m sd_model_manager registry scan --path /path/to/models
python -m sd_model_manager registry list
pytest tests/sd_model_manager/registry/test_scanner.py::test_specific_case -v
```

**Step 3**: Define checkpoints
```markdown
**Expected Behavior**:
- [What should happen]

**Actual Behavior**:
- [What actually happens]

**Checkpoints**:
- [ ] Log file: Check for [specific error message]
- [ ] Database: Verify [table/field state]
- [ ] UI: Check [component behavior]
- [ ] API: Verify [endpoint response]
```

### Phase 3: Context Extraction

**Step 1**: Find relevant code sections
```bash
# Extract function/class causing issue
rg -A 20 "def scan\(|class.*Scanner" src/sd_model_manager/registry/scanner.py

# Find error handling code
rg -B 5 -A 10 "except.*Error|raise.*Error" src/sd_model_manager/registry/scanner.py
```

**Step 2**: Find related tests
```bash
# Find test coverage for affected code
rg -l "test.*scan.*empty|test.*metadata" tests/sd_model_manager/
```

---

## Output Format

### Bug Reproduction Checklist

```markdown
# Bug Reproduction Report: [Short Description]

**Date**: [YYYY-MM-DD]
**Reporter**: [Name/System]
**Severity**: üî¥ Critical / üü† High / üü° Medium / üü¢ Low
**Component**: [Affected module/feature]

---

## üìã Bug Summary

**Symptom**: [One-line description of observable issue]

**Error Message** (if available):
\`\`\`
[Stack trace or error message]
\`\`\`

**Affected Files**:
- `src/sd_model_manager/[path]:[line]`
- `tests/sd_model_manager/[path]:[line]`

---

## üîç Reproduction Steps

### Prerequisites
\`\`\`bash
# Environment setup
python --version  # Expected: 3.11+
uv --version      # Check uv is installed

# Install dependencies
uv sync

# Prepare test data (if needed)
mkdir -p test_data/models/loras
touch test_data/models/loras/test.safetensors
\`\`\`

### Step-by-Step Reproduction

1. **Setup**: [Initial state preparation]
   \`\`\`bash
   [command]
   \`\`\`

2. **Execute**: [Trigger the bug]
   \`\`\`bash
   [command that causes bug]
   \`\`\`

3. **Observe**: [Where to see the issue]
   - Check console output for: [expected error]
   - Check log file: `logs/app.log` for: [pattern]
   - Check [other location]

### Expected vs Actual Behavior

**Expected**:
- [What should happen]
- [Expected output/state]

**Actual**:
- [What actually happens]
- [Error message/incorrect behavior]

---

## üéØ Verification Checkpoints

After reproduction, verify:
- [ ] **Console Output**: [What to check]
- [ ] **Log File**: `tail -20 logs/app.log` shows [pattern]
- [ ] **Database State**: [Query to run / table to check]
- [ ] **File System**: Check [directory/file state]
- [ ] **API Response**: [Endpoint to test / expected response]

---

## üî¨ Debug Information

### Relevant Code Section
**File**: `src/sd_model_manager/[path]:[line]`
\`\`\`python
[Relevant code snippet extracted with rg/Read]
\`\`\`

### Related Tests
**File**: `tests/sd_model_manager/[path]:[line]`
- Test coverage: [existing tests that should catch this]
- Missing coverage: [what test should be added]

### Recent Changes
\`\`\`bash
# Last 5 commits affecting this component
git log --oneline -5 -- src/sd_model_manager/[component]/
\`\`\`

---

## üõ†Ô∏è Diagnosis Hints

### Potential Root Causes
1. [Hypothesis 1 based on code analysis]
2. [Hypothesis 2 based on error pattern]
3. [Hypothesis 3 based on recent changes]

### Investigation Commands
\`\`\`bash
# Debug command 1: [Purpose]
[command with --verbose or --debug flag]

# Debug command 2: [Purpose]
[command to inspect state]

# Debug command 3: [Purpose]
pytest tests/[specific test] -v -s  # Run with print output
\`\`\`

---

## ‚úÖ Fix Verification Checklist

After fix implementation:
- [ ] Bug reproduction steps no longer trigger error
- [ ] All existing tests still pass: `pytest tests/sd_model_manager/ -v`
- [ ] New test added to prevent regression
- [ ] Edge cases considered and tested
- [ ] Documentation updated (if behavior changed)
- [ ] Code review completed
- [ ] Manual testing in realistic scenario

---

## üìù Notes

[Additional context, workarounds, or related issues]

---

**Generated by**: Bug Reproduction Assistant
**Status**: üîç Investigation / üîß In Progress / ‚úÖ Fixed / ‚è≠Ô∏è Deferred
**Related Issues**: [GitHub issue number / PR link]
```

---

## Quick Checklist Template (Minimal Version)

For simple bugs, use this abbreviated format:

```markdown
# Bug: [Short Description]

**Error**: [One-line error message]
**File**: `[path]:[line]`

## Reproduce
\`\`\`bash
[single command that triggers bug]
\`\`\`

## Expected vs Actual
- Expected: [what should happen]
- Actual: [what happens]

## Fix Verification
- [ ] Bug no longer reproduces
- [ ] Tests pass
- [ ] New test added
```

---

## Success Criteria

Bug report is useful when:
- ‚úÖ Anyone can reproduce the bug following the steps
- ‚úÖ All commands are copy-paste ready
- ‚úÖ Checkpoints clearly define expected vs actual behavior
- ‚úÖ Relevant code sections are identified
- ‚úÖ Fix verification steps are provided

## Integration

### With Existing Workflows
- **progress-reports**: Output goes to `docs/progress-reports/bug-*.md`
- **codex-review-agent**: Can reference bug reports during code review
- **test-quality-checker**: Can identify missing test coverage for bug

### With Issue Tracking
Bug reports can be:
1. Copied to GitHub Issues
2. Referenced in PR descriptions
3. Linked from task completion reports

---

## Example Invocation

```
"Generate bug reproduction for scanner crash on empty directory"
"Create reproduction steps for 'ModelScanError: directory not found'"
"Generate bug checklist for failing test_scan_handles_missing_civitai_metadata"
```

---

## Usage Tips

**When to Use**:
- ‚ùå Don't use for expected behavior or feature requests
- ‚úÖ Use when actual behavior differs from expected
- ‚úÖ Use when tests fail unexpectedly
- ‚úÖ Use when error messages are unclear

**Information to Provide**:
- Error message or stack trace
- Expected vs actual behavior
- Steps taken before bug occurred
- Relevant file paths or component names

**Output Location**:
Always save to: `docs/progress-reports/bug-[YYYYMMDD]-[description].md`

Example filenames:
- `bug-20251104-scanner-empty-dir.md`
- `bug-20251104-metadata-parse-fail.md`
- `bug-20251104-api-timeout.md`
